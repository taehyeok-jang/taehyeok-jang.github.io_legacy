---
layout: post
title: Decaton - High throughput asynchronous task processing based on Apache Kafka - 1
subheading: 
author: taehyeok-jang
categories: [stream-processing]
tags: [stream-processing, kafka, decaton]
---



## Introduction 

Decaton은 Apache Kafka 기반의 streaming task processing 프레임워크입니다. Kafka consumer는 single thread로 동작하는데 이는 동시처리에 따라 순차처리 및 offset 관리가 어려워지면서 여러 문제가 발생하기 때문입니다. Decaton은 이를 극복하여 consumer에서 하나의 partition로부터 소비되는 record의 동시처리를 가능하게 하도록 설계되었습니다. 아래는 Decaton에서 지원하는 세가지 성질입니다. 

- 하나의 partition으로부터 오는 record를 동시처리(multi-thread or asynchronous) 
- record key 별 순서처리 보장
- record들이 처리되는 순서와는 상관 없이 at-least-once semantic을 보장  

아래 두가지 성질은 Kafka consumer에서 기본적으로 지원하는 성질인데 streaming task 처리의 계산 결과 보장 및 일관성 유지 등 데이터 정합성을 위해서 아주 중요합니다. Decaton은 위 성질을 만족하면서도 동시처리를 제공하여 보다 적은 수의 서버로도 처리 성능을 극대화할 수 있도록 하였습니다. 

Decaton은 본래 messenger app인 LINE에서 내부적으로 사용되는 라이브러리였습니다. 각 stream에서 초당 1백만개가 넘는 I/O intensive한 태스크를 처리하는 시스템에서 디자인 및 최적화되어 그 성능과 안정성을 검증 받았고, 이후 오픈소스화 한 프로젝트입니다. 이번 글에서는 Kafka consumer에서 왜 동시처리가 필요한지, Decaton은 이를 해결하기 위해서 어떻게 설계되었으며 어떤 기능을 지원하는지에 대해 알아보겠습니다. 





## Why Concurrent Processing in Kafka Consumer

Kafka consumer에서 왜 동시처리가 필요할까요? 이를 이해하기 위해서 Kafka에서 메시지를 처리하는 방식에 대해서 알아보겠습니다. 

[![img](https://1.bp.blogspot.com/-W27stRlxqhg/X2dNfFR1tnI/AAAAAAAADms/cjwuIhdOVhUHIIyMGcZPjetWu6492bflgCLcBGAsYHQ/s320/kafka-architecture-topic-partition-layout-offsets.png)](https://1.bp.blogspot.com/-W27stRlxqhg/X2dNfFR1tnI/AAAAAAAADms/cjwuIhdOVhUHIIyMGcZPjetWu6492bflgCLcBGAsYHQ/s796/kafka-architecture-topic-partition-layout-offsets.png)



Kafka는 topic을 단위로 메시지를 발행 및 저장합니다. 한 topic의 메세지들은 partition이라는 분산처리 단위로 위 그림에서와 같이 여러 partition에 나누어져서 저장되며 각 partition 내의 메시지들은 순서대로 read/write가 되는 것을 보장합니다. 

하나의 topic으로 발행되는 메시지들은 consumer group이라는 여러 consumer들의 집합에서 각각 처리합니다. 한 consumer group에서 처리할 수 있는 메시지의 양보다 producer가 생성하는 message의 양이 더 많으면 (즉, producer의 throughput이 더 높으면) 해당 메시지들은 처리가 지연되어 broker 상에 계속 쌓이게 됩니다. 이를 해결하기 위해서 consumer group에서 더 많은 메시지를 처리할 수 있도록 consumer instance를 추가할 수 있습니다. 하지만 Kafka에서는 하나의 partition을 여러 consumer에서 처리하는 것이 불가능하므로 consumer group의 최대 concurrency는 partition 개수로 한정됩니다. 

[![img](https://1.bp.blogspot.com/--0_u2uJBpe4/X2dPlY8RPHI/AAAAAAAADm8/BgDN-i6cXgEx49PBkfcP1eKUOZhEVs0_QCLcBGAsYHQ/s320/consumer-group-1.png)](https://1.bp.blogspot.com/--0_u2uJBpe4/X2dPlY8RPHI/AAAAAAAADm8/BgDN-i6cXgEx49PBkfcP1eKUOZhEVs0_QCLcBGAsYHQ/s990/consumer-group-1.png)

[![img](https://1.bp.blogspot.com/-yWedZsFqixU/X2dP4r1BSLI/AAAAAAAADnM/hw4-JGvLhmICEEKitia_EgdzhoVaabcBACLcBGAsYHQ/s320/consumer-group-2.png)](https://1.bp.blogspot.com/-yWedZsFqixU/X2dP4r1BSLI/AAAAAAAADnM/hw4-JGvLhmICEEKitia_EgdzhoVaabcBACLcBGAsYHQ/s1112/consumer-group-2.png)

[![img](https://1.bp.blogspot.com/-Yl_O6V2Cc84/X2dP7jTZqoI/AAAAAAAADnQ/95X-80PvV2E7rFTxjT65DWfEmV-JhmxVgCLcBGAsYHQ/s320/consumer-group-3.png)](https://1.bp.blogspot.com/-Yl_O6V2Cc84/X2dP7jTZqoI/AAAAAAAADnQ/95X-80PvV2E7rFTxjT65DWfEmV-JhmxVgCLcBGAsYHQ/s916/consumer-group-3.png)



Kafka를 활용하는 여러 사례들에서 위 전략으로도 충분히 우수한 성능을 보였습니다. 하지만 사용 중인 Kafka에서 동시처리 성능을 높여야 하는 상황에서 다음의 문제점이 있을 수 있습니다. 

- consumer instance를 추가하면서 (horizontal scaling) 비용이 추가로 발생하며, consumer group coordinator의 workload가 증가하고 network traffic이 더 발생할 수 있습니다. 또한 consumer instance들을 관리하는 consumer group coordinator의 부하가 증가합니다. 
- consumer instance의 개수를 partition 개수만큼 최대로 늘렸는데도 요구되는 성능을 충족시키지 못할 수도 있습니다. 남은 유일한 방법은 partition을 추가하는 것이지만 key based ordering이 rebalancing으로 인해 무너지고 브로커에 또 다른 부하를 발생시킵니다
- consumer에서 처리하는 작업이 CPU intensive한 작업이 아니라 대기 시간을 요하는 I/O intensive 작업이라면 instance를 추가하는 것으로부터 얻는 효용이 크지 않습니다. consumer의 CPU 사용률이 높지 않은데도 instance를 추가하는 것은 리소스를 낭비하는 것입니다

 

## Multi-Threaded Message Consumption with Consumer

[https://www.confluent.io/blog/kafka-consumer-multi-threaded-messaging/](https://www.confluent.io/blog/kafka-consumer-multi-threaded-messaging/)

Kafka 엔터프라이즈 솔루션을 제공하는 Confluent 사의 블로그에서 동일한 문제를 다루고 있습니다. 마찬가지로 consumer의 single thread 모델의 한계점을 지적하고 있으며, consumption과 processing을 각각 main thread와 별도의 thread pool로 처리하는 multi thread 모델을 제안합니다. 



### Motivation for a Multi-Threaded Consumer Architecture 

Kafka consumer의 single thread 모델에서 발생하는 한계점은 다음과 같습니다.

1. slow processing을 개선하기 위해서 consumer 설정을 조정할 수 있지만 완전한 해결책이 될 수 없습니다

Kafka consumer의 max.poll.interval.ms의 default 설정은 5분입니다. 이것을 초과하면 해당 consumer는 죽은 것으로 처리되어 group rebalancing이 발생합니다. 만약 consumer가 처리해야 할 task가 오랜 시간이 요구되는 task라면 다음과 같이 설정을 조정합니다.

- max.poll.records을 더 낮게 설정하여 한번에 처리하는 레코드의 수를 줄입니다
- max.poll.interval.ms을 더 높게 설정하여 처리 대기시간을 늘립니다. 

위 두가지 설정을 같이 조정하는 것을 시도할 수 있지만 가변적인 어플리케이션 환경에서 완벽한 값을 찾는 것이 매우 어렵습니다. 

2. 실패한 메시지에 대한 예외처리는 어렵고 복잡하며 또 다른 문제를 발생시킵니다

예외 처리를 포함하여 메시지를 처리하는 로직은 어플리케이션 의존적입니다. 처리 도중 에러 발생 시에는 아래와 같은 방식으로 처리하는 것을 고려할 수 있습니다.

- 처리를 멈추고 consumer를 close 합니다 (그전에 수차례 재시도 처리를 합니다)
- dead letter queue로 레코드를 보내고 다음 레코드로 넘어갑니다 (그전에 수차례 재시도 처리를 합니다)
- 레코드를 성공적으로 처리할 때까지 재시도 처리합니다 (영원히 재시도 할 수도 있습니다)

세번째 방식 또한 어떤 어플리케이션에서는 적절한 처리 방식입니다. 하지만 max.poll.interval.ms를 초과하는 경우 consumer group에서 kickout 당하게 되고 해당 메시지는 영원히 처리되지 않을 수도 있습니다. 

multi thread 모델은 위 세가지 문제점들에 대한 개선 방안이 될 수 있습니다. 추가적인 consumer intance 없이도 처리 성능을 향상시킵니다. slow processing으로부터 오는 consumer 설정, 어렵고 복잡한 예외처리 문제로부터 자유로워질 수 있습니다. 



### Multi-threaded Kafka Consumer 

![img](https://1.bp.blogspot.com/-so8zts-kbNQ/X2dVDCi_PEI/AAAAAAAADnk/1WbPw9GFcAE4V4W98swq2eu66LJhXh4XgCLcBGAsYHQ/s320/decoupling-consumption.png)

multi thread 처리를 위한 naive approach로 별도의 thread pool을 통해 태스크들을 동시처리하는 방식을 생각할 수 있습니다. commit과 관련된 consumer default 설정으로 automatic offset commit으로, consumer에서 poll을 통해 여러 메시지들을 가져온 다음 thread pool에서 비동기로 처리하는 방식입니다. 이 방식에는 다음과 같은 문제점이 있습니다.

- 한 partition으로부터 가져온 메시지들이 병렬처리되기 때문에 메시지 처리순서가 보장되지 않습니다
- 특정 레코드가 처리되기 전에 offset commit이 일어납니다

동시처리를 통해 single thread 모델을 개선하는 것이 목적이지만, 위 모델에서는 single thread 모델이 지원하는 parition 별 순서처리 보장과 at-least-once semantic이 지켜지지 않습니다. 이 문제를 해결하기 위해 다음과 같이 제안하고 있습니다.



#### Ensuring processing order guarantees

한 partition에서 가져온 레코드들은 하나의 thread에서 처리하게 합니다. 즉, 하나의 consumer에서 여러 partition으로부터 레코드들을 가져오면 이를 partition 별로 나눈 다음 각 thread에 분배합니다. 이렇게 하면 각 partition 별로는 하나의 thread에서 처리되므로 순서가 지켜집니다. 또한 thread가 한 partition의 레코드들을 모두 처리하기 전에 추가적으로 레코드들을 가져오면 순서 역전이 발생할 수 있으니 thread의 시작 및 완료 시점에 해당 partition으로부터 fetch를 중단 및 재시작합니다. 

#### Commiting offsets

동시처리를 하면서 offset을 관리하기 위해서는 Kafka consumer의 default 설정인 automatic offset commit은 off 해야합니다. 개별 thread에 할당된 한 partition의 레코드들이 언제 처리되었는지 main thread는 알 수 없기 때문입니다. 대신 thread에서 작업이 완료되면 완료 offset을 남기고 백그라운드에서 대상 partition에 commit 하도록 합니다. 

#### Handling group rebalances

consumer 내에서 여러 partition에 대한 동시처리를 하고 있을 때 consumer group rebalancing이 발생할 수 있습니다. 이때 특정 partition이 다른 consumer에 할당되면서 레코드가 중복처리 될 수 있습니다. 이는 rebalancing 대상인 partition의 레코드들이 모두 처리되고 commit이 완료되었는지를 확인함으로써 해결할 수 있습니다. consumer subscribe 시 ConsumerRebalanceListener를 등록하여 rebalancing이 발생했을 때 위와 같이 처리할 수 있도록 합니다.  



## Limitation 

위 모델에도 한계점은 있습니다. 한 consumer에서 여러 partition을 처리할 수 있도록 하여 병렬성은 높였지만 여전히 한 partition의 메시지들을 동시에 처리하지는 못합니다. 운영 상의 이유로 partition 개수를 더 추가하기 어렵거나 특정 partition에서만 레코드가 지나치게 발행되는 등의 상황이 여전히 문제로 남아있습니다. 결국 한 partition의 레코드들을 동시에 처리할 수 있어야합니다. 즉, partition-level parallelism 보다 더 높은 수준의 parallelism이 필요합니다. 





## References

- https://github.com/line/decaton
- https://www.confluent.io/blog/kafka-consumer-multi-threaded-messaging/
- https://www.confluent.io/blog/introducing-confluent-parallel-message-processing-client/
- https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/
- https://kafka.apache.org
- https://dzone.com/articles/kafka-topic-architecture-replication-failover-and
- LINE Engineering Blog 
  - https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-1/
  - https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-2/
  - https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-3/
  - https://engineering.linecorp.com/ko/blog/decaton-case-studies/
  - https://speakerdeck.com/line_devday2020/decaton-high-performance-task-processing-with-kafka?slide=16

